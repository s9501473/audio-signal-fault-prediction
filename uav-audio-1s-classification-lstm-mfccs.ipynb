{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7518995,"sourceType":"datasetVersion","datasetId":4275198}],"dockerImageVersionId":30664,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing the libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport librosa\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense, Dropout\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.optimizers import Adam","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-02T12:32:11.884200Z","iopub.execute_input":"2024-03-02T12:32:11.885470Z","iopub.status.idle":"2024-03-02T12:32:11.894245Z","shell.execute_reply.started":"2024-03-02T12:32:11.885397Z","shell.execute_reply":"2024-03-02T12:32:11.893139Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# 加載音頻訊號","metadata":{}},{"cell_type":"code","source":"data_path = '/kaggle/input/recoding-data/UAV Recordings 1s/UAV Recordings 1s'","metadata":{"execution":{"iopub.status.busy":"2024-03-02T12:32:11.896436Z","iopub.execute_input":"2024-03-02T12:32:11.897074Z","iopub.status.idle":"2024-03-02T12:32:11.910749Z","shell.execute_reply.started":"2024-03-02T12:32:11.897042Z","shell.execute_reply":"2024-03-02T12:32:11.909495Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"# 音頻訊號進行MFCCs特徵提取","metadata":{}},{"cell_type":"code","source":"def load_data(data_dir):\n    datasets = []\n    labels = []\n    categories = os.listdir(data_dir)\n    for index, folder in enumerate(categories):\n        for filename in os.listdir(data_dir+\"/\"+folder):\n            data, sampling_rate = librosa.load(data_dir+\"/\"+folder+\"/\"+filename)\n            mfccs_features = librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=80)\n            mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n            datasets.append(np.array(mfccs_scaled_features))\n            labels.append(categories[index])\n    return np.array(datasets), np.array(labels)\n\ndatasets, labels = load_data(data_path)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T12:32:11.912359Z","iopub.execute_input":"2024-03-02T12:32:11.912774Z","iopub.status.idle":"2024-03-02T12:34:15.502403Z","shell.execute_reply.started":"2024-03-02T12:32:11.912739Z","shell.execute_reply":"2024-03-02T12:34:15.500394Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"datasets = datasets.astype('float32')\n\nlabelencoder = LabelEncoder()\n\nlabelsOneHot = to_categorical(labelencoder.fit_transform(labels))","metadata":{"execution":{"iopub.status.busy":"2024-03-02T12:34:15.514219Z","iopub.execute_input":"2024-03-02T12:34:15.520529Z","iopub.status.idle":"2024-03-02T12:34:15.535713Z","shell.execute_reply.started":"2024-03-02T12:34:15.520442Z","shell.execute_reply":"2024-03-02T12:34:15.534071Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# 切分成訓練資料、測試資料，8:2的比例","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(datasets, labelsOneHot, test_size = 0.2, stratify = labelsOneHot, random_state = 3)\n\nprint(\"----------Train-------------\")\nprint(X_train.shape)\n\nprint(\"----------Test--------------\")\nprint(X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T12:34:15.543450Z","iopub.execute_input":"2024-03-02T12:34:15.548705Z","iopub.status.idle":"2024-03-02T12:34:15.649731Z","shell.execute_reply.started":"2024-03-02T12:34:15.548625Z","shell.execute_reply":"2024-03-02T12:34:15.648398Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"----------Train-------------\n(4512, 80)\n----------Test--------------\n(1128, 80)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 類別數量","metadata":{}},{"cell_type":"code","source":"num_classes = len(np.unique(labels))","metadata":{"execution":{"iopub.status.busy":"2024-03-02T12:34:15.652280Z","iopub.execute_input":"2024-03-02T12:34:15.653348Z","iopub.status.idle":"2024-03-02T12:34:15.659704Z","shell.execute_reply.started":"2024-03-02T12:34:15.653282Z","shell.execute_reply":"2024-03-02T12:34:15.658555Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"# 建立LSTM模型","metadata":{}},{"cell_type":"code","source":"# 建立一個Sequential模型\nmodel = Sequential()\n\n# 添加一個LSTM層，設定隱藏層的神經元數量為32\nmodel.add(LSTM(128, activation='relu', return_sequences = True, input_shape = (datasets.shape[1], 1)))\n\nmodel.add(LSTM(64, activation='relu'))\n\nmodel.add(Dense(64, activation='relu'))\n\n# 使用Dropout防止過度擬合\nmodel.add(Dropout(0.25))\n\n# 輸出層，有num_classes個類別，所以輸出層的輸出維度為num_classes\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# 選擇損失函數、優化方法及成效衡量方式\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-02T12:34:15.662935Z","iopub.execute_input":"2024-03-02T12:34:15.663383Z","iopub.status.idle":"2024-03-02T12:34:15.779776Z","shell.execute_reply.started":"2024-03-02T12:34:15.663345Z","shell.execute_reply":"2024-03-02T12:34:15.778630Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_3\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m66,560\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m325\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,560</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m120,453\u001b[0m (470.52 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120,453</span> (470.52 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m120,453\u001b[0m (470.52 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120,453</span> (470.52 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"# 模型訓練","metadata":{}},{"cell_type":"code","source":"train_history = model.fit(X_train, y_train, validation_split=0.2, batch_size = 100, epochs = 100, verbose = 2)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T12:34:15.781282Z","iopub.execute_input":"2024-03-02T12:34:15.781735Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/100\n46/46 - 12s - 267ms/step - accuracy: 0.2463 - loss: 14348.4902 - val_accuracy: 0.1883 - val_loss: 106.2049\nEpoch 2/100\n46/46 - 8s - 183ms/step - accuracy: 0.2294 - loss: 1483.6798 - val_accuracy: 0.2315 - val_loss: 1327.7349\nEpoch 3/100\n46/46 - 8s - 177ms/step - accuracy: 0.2167 - loss: 813.2113 - val_accuracy: 0.1705 - val_loss: 150.9724\nEpoch 4/100\n46/46 - 8s - 175ms/step - accuracy: 0.2095 - loss: 373.4822 - val_accuracy: 0.3045 - val_loss: 88.3031\nEpoch 5/100\n46/46 - 11s - 232ms/step - accuracy: 0.2147 - loss: 184.2641 - val_accuracy: 0.2658 - val_loss: 51.1464\nEpoch 6/100\n46/46 - 10s - 216ms/step - accuracy: 0.2145 - loss: 82.6530 - val_accuracy: 0.2248 - val_loss: 20.8499\nEpoch 7/100\n46/46 - 8s - 177ms/step - accuracy: 0.2291 - loss: 42.0361 - val_accuracy: 0.1783 - val_loss: 31.4125\nEpoch 8/100\n46/46 - 8s - 179ms/step - accuracy: 0.2291 - loss: 110.8729 - val_accuracy: 0.2802 - val_loss: 47.0433\nEpoch 9/100\n46/46 - 10s - 228ms/step - accuracy: 0.2729 - loss: 46.0513 - val_accuracy: 0.3156 - val_loss: 22.9294\nEpoch 10/100\n46/46 - 8s - 177ms/step - accuracy: 0.3045 - loss: 34.6827 - val_accuracy: 0.3101 - val_loss: 27.7099\nEpoch 11/100\n46/46 - 8s - 177ms/step - accuracy: 0.3048 - loss: 28.3587 - val_accuracy: 0.3156 - val_loss: 21.8453\nEpoch 12/100\n46/46 - 10s - 226ms/step - accuracy: 0.3114 - loss: 30.6513 - val_accuracy: 0.3123 - val_loss: 24.4587\nEpoch 13/100\n46/46 - 10s - 217ms/step - accuracy: 0.3089 - loss: 30.1728 - val_accuracy: 0.3068 - val_loss: 24.9540\nEpoch 14/100\n46/46 - 10s - 224ms/step - accuracy: 0.3142 - loss: 26.6392 - val_accuracy: 0.3134 - val_loss: 20.6794\nEpoch 15/100\n46/46 - 10s - 219ms/step - accuracy: 0.3148 - loss: 24.2552 - val_accuracy: 0.3079 - val_loss: 18.6355\nEpoch 16/100\n46/46 - 8s - 182ms/step - accuracy: 0.3153 - loss: 29.2763 - val_accuracy: 0.3101 - val_loss: 17.6642\nEpoch 17/100\n46/46 - 8s - 175ms/step - accuracy: 0.3112 - loss: 26.9427 - val_accuracy: 0.3156 - val_loss: 15.8331\nEpoch 18/100\n46/46 - 8s - 177ms/step - accuracy: 0.3145 - loss: 20.8857 - val_accuracy: 0.3068 - val_loss: 15.9681\nEpoch 19/100\n46/46 - 11s - 228ms/step - accuracy: 0.3139 - loss: 33.6232 - val_accuracy: 0.3012 - val_loss: 16.5693\nEpoch 20/100\n46/46 - 10s - 216ms/step - accuracy: 0.3106 - loss: 23.0988 - val_accuracy: 0.3056 - val_loss: 13.2349\nEpoch 21/100\n46/46 - 10s - 224ms/step - accuracy: 0.3103 - loss: 20.5702 - val_accuracy: 0.2957 - val_loss: 20.3777\nEpoch 22/100\n46/46 - 8s - 178ms/step - accuracy: 0.3167 - loss: 18.8726 - val_accuracy: 0.3056 - val_loss: 18.2507\nEpoch 23/100\n46/46 - 8s - 184ms/step - accuracy: 0.3139 - loss: 17.7227 - val_accuracy: 0.3045 - val_loss: 15.2568\nEpoch 24/100\n46/46 - 10s - 214ms/step - accuracy: 0.3073 - loss: 14.1423 - val_accuracy: 0.3068 - val_loss: 9.4588\nEpoch 25/100\n46/46 - 10s - 225ms/step - accuracy: 0.3117 - loss: 17.7311 - val_accuracy: 0.3156 - val_loss: 10.7475\nEpoch 26/100\n46/46 - 10s - 227ms/step - accuracy: 0.3139 - loss: 18.2995 - val_accuracy: 0.3212 - val_loss: 10.5092\nEpoch 27/100\n46/46 - 10s - 216ms/step - accuracy: 0.3145 - loss: 17.7311 - val_accuracy: 0.3245 - val_loss: 6.6763\nEpoch 28/100\n46/46 - 8s - 178ms/step - accuracy: 0.3078 - loss: 19.8016 - val_accuracy: 0.3256 - val_loss: 7.1134\nEpoch 29/100\n46/46 - 8s - 174ms/step - accuracy: 0.3112 - loss: 14.5562 - val_accuracy: 0.3300 - val_loss: 5.4241\nEpoch 30/100\n46/46 - 10s - 224ms/step - accuracy: 0.3139 - loss: 13.7272 - val_accuracy: 0.3223 - val_loss: 5.7272\nEpoch 31/100\n46/46 - 10s - 224ms/step - accuracy: 0.3120 - loss: 12.8636 - val_accuracy: 0.3278 - val_loss: 7.3833\nEpoch 32/100\n46/46 - 8s - 178ms/step - accuracy: 0.3078 - loss: 13.2094 - val_accuracy: 0.3289 - val_loss: 6.8726\nEpoch 33/100\n46/46 - 11s - 233ms/step - accuracy: 0.3106 - loss: 13.1645 - val_accuracy: 0.3267 - val_loss: 8.4027\nEpoch 34/100\n46/46 - 8s - 177ms/step - accuracy: 0.3148 - loss: 13.3090 - val_accuracy: 0.3267 - val_loss: 7.6152\nEpoch 35/100\n46/46 - 10s - 224ms/step - accuracy: 0.3084 - loss: 16.9194 - val_accuracy: 0.3212 - val_loss: 5.3704\nEpoch 36/100\n46/46 - 10s - 228ms/step - accuracy: 0.3095 - loss: 11.2427 - val_accuracy: 0.3267 - val_loss: 6.7978\nEpoch 37/100\n46/46 - 8s - 178ms/step - accuracy: 0.3170 - loss: 8.4353 - val_accuracy: 0.3267 - val_loss: 7.2026\nEpoch 38/100\n46/46 - 10s - 221ms/step - accuracy: 0.3109 - loss: 11.8898 - val_accuracy: 0.3223 - val_loss: 5.8503\nEpoch 39/100\n46/46 - 10s - 223ms/step - accuracy: 0.3145 - loss: 11.0100 - val_accuracy: 0.3289 - val_loss: 5.2538\nEpoch 40/100\n46/46 - 10s - 223ms/step - accuracy: 0.3098 - loss: 9.6138 - val_accuracy: 0.3278 - val_loss: 3.5953\nEpoch 41/100\n46/46 - 10s - 219ms/step - accuracy: 0.3134 - loss: 11.2917 - val_accuracy: 0.3267 - val_loss: 2.8336\nEpoch 42/100\n46/46 - 8s - 177ms/step - accuracy: 0.3170 - loss: 9.2873 - val_accuracy: 0.3355 - val_loss: 2.5745\nEpoch 43/100\n46/46 - 8s - 185ms/step - accuracy: 0.3112 - loss: 7.9313 - val_accuracy: 0.3311 - val_loss: 2.5603\nEpoch 44/100\n46/46 - 8s - 179ms/step - accuracy: 0.3173 - loss: 8.7921 - val_accuracy: 0.3223 - val_loss: 4.5936\nEpoch 45/100\n46/46 - 10s - 219ms/step - accuracy: 0.3098 - loss: 9.7041 - val_accuracy: 0.3145 - val_loss: 6.1903\nEpoch 46/100\n46/46 - 11s - 232ms/step - accuracy: 0.3195 - loss: 8.9942 - val_accuracy: 0.3090 - val_loss: 2.6500\nEpoch 47/100\n46/46 - 8s - 178ms/step - accuracy: 0.3162 - loss: 7.5296 - val_accuracy: 0.3034 - val_loss: 3.5106\nEpoch 48/100\n46/46 - 8s - 175ms/step - accuracy: 0.3109 - loss: 8.7221 - val_accuracy: 0.3079 - val_loss: 2.4318\nEpoch 49/100\n46/46 - 10s - 224ms/step - accuracy: 0.3123 - loss: 8.7787 - val_accuracy: 0.3156 - val_loss: 2.3997\nEpoch 50/100\n46/46 - 8s - 183ms/step - accuracy: 0.3173 - loss: 8.3648 - val_accuracy: 0.3167 - val_loss: 2.2685\nEpoch 51/100\n46/46 - 10s - 215ms/step - accuracy: 0.3114 - loss: 8.7177 - val_accuracy: 0.3200 - val_loss: 2.0679\nEpoch 52/100\n46/46 - 10s - 224ms/step - accuracy: 0.3101 - loss: 8.9357 - val_accuracy: 0.2990 - val_loss: 2.0875\nEpoch 53/100\n46/46 - 8s - 182ms/step - accuracy: 0.3153 - loss: 7.5745 - val_accuracy: 0.3101 - val_loss: 2.0624\nEpoch 54/100\n46/46 - 8s - 180ms/step - accuracy: 0.3162 - loss: 8.5321 - val_accuracy: 0.3068 - val_loss: 2.3136\nEpoch 55/100\n46/46 - 10s - 218ms/step - accuracy: 0.3126 - loss: 8.6293 - val_accuracy: 0.3056 - val_loss: 2.8505\nEpoch 56/100\n46/46 - 10s - 225ms/step - accuracy: 0.3148 - loss: 7.4464 - val_accuracy: 0.3101 - val_loss: 2.6532\nEpoch 57/100\n46/46 - 11s - 229ms/step - accuracy: 0.3153 - loss: 9.9503 - val_accuracy: 0.3178 - val_loss: 3.0484\nEpoch 58/100\n46/46 - 8s - 176ms/step - accuracy: 0.3109 - loss: 7.9237 - val_accuracy: 0.3167 - val_loss: 2.8788\nEpoch 59/100\n46/46 - 8s - 176ms/step - accuracy: 0.3145 - loss: 6.5825 - val_accuracy: 0.3212 - val_loss: 2.3613\nEpoch 60/100\n46/46 - 11s - 231ms/step - accuracy: 0.3173 - loss: 6.3277 - val_accuracy: 0.3245 - val_loss: 2.1109\nEpoch 61/100\n46/46 - 10s - 213ms/step - accuracy: 0.3106 - loss: 8.1329 - val_accuracy: 0.3189 - val_loss: 2.5036\nEpoch 62/100\n46/46 - 8s - 176ms/step - accuracy: 0.3126 - loss: 7.5104 - val_accuracy: 0.3234 - val_loss: 2.2597\nEpoch 63/100\n46/46 - 10s - 222ms/step - accuracy: 0.3131 - loss: 6.1875 - val_accuracy: 0.3234 - val_loss: 2.0028\nEpoch 64/100\n46/46 - 10s - 226ms/step - accuracy: 0.3126 - loss: 6.4776 - val_accuracy: 0.3311 - val_loss: 2.0607\nEpoch 65/100\n46/46 - 10s - 223ms/step - accuracy: 0.3150 - loss: 6.4935 - val_accuracy: 0.3300 - val_loss: 2.0883\nEpoch 66/100\n46/46 - 8s - 180ms/step - accuracy: 0.3195 - loss: 6.2699 - val_accuracy: 0.3267 - val_loss: 3.3053\nEpoch 67/100\n46/46 - 8s - 183ms/step - accuracy: 0.3128 - loss: 6.2353 - val_accuracy: 0.3267 - val_loss: 3.5188\nEpoch 68/100\n46/46 - 10s - 216ms/step - accuracy: 0.3087 - loss: 6.6362 - val_accuracy: 0.3267 - val_loss: 2.8855\nEpoch 69/100\n46/46 - 10s - 222ms/step - accuracy: 0.3103 - loss: 5.8374 - val_accuracy: 0.3234 - val_loss: 2.9418\nEpoch 70/100\n46/46 - 10s - 228ms/step - accuracy: 0.3142 - loss: 5.1375 - val_accuracy: 0.3333 - val_loss: 2.7541\nEpoch 71/100\n46/46 - 8s - 178ms/step - accuracy: 0.3156 - loss: 6.2286 - val_accuracy: 0.3256 - val_loss: 2.7588\nEpoch 72/100\n46/46 - 10s - 222ms/step - accuracy: 0.3145 - loss: 5.7268 - val_accuracy: 0.3245 - val_loss: 3.3952\nEpoch 73/100\n46/46 - 8s - 178ms/step - accuracy: 0.3186 - loss: 5.3631 - val_accuracy: 0.3289 - val_loss: 3.6484\nEpoch 74/100\n46/46 - 8s - 184ms/step - accuracy: 0.3178 - loss: 5.4114 - val_accuracy: 0.3223 - val_loss: 3.4698\nEpoch 75/100\n46/46 - 10s - 217ms/step - accuracy: 0.3123 - loss: 4.2820 - val_accuracy: 0.3234 - val_loss: 3.3836\nEpoch 76/100\n46/46 - 10s - 228ms/step - accuracy: 0.3206 - loss: 3.9973 - val_accuracy: 0.3300 - val_loss: 3.1229\nEpoch 77/100\n46/46 - 10s - 223ms/step - accuracy: 0.3175 - loss: 4.6806 - val_accuracy: 0.3245 - val_loss: 3.4772\nEpoch 78/100\n46/46 - 10s - 216ms/step - accuracy: 0.3206 - loss: 4.3080 - val_accuracy: 0.3278 - val_loss: 2.8688\nEpoch 79/100\n46/46 - 8s - 177ms/step - accuracy: 0.3087 - loss: 5.0730 - val_accuracy: 0.3223 - val_loss: 2.7675\nEpoch 80/100\n46/46 - 10s - 221ms/step - accuracy: 0.3200 - loss: 4.3804 - val_accuracy: 0.3245 - val_loss: 2.8794\nEpoch 81/100\n46/46 - 10s - 224ms/step - accuracy: 0.3134 - loss: 4.5812 - val_accuracy: 0.3289 - val_loss: 2.6664\nEpoch 82/100\n46/46 - 8s - 175ms/step - accuracy: 0.3162 - loss: 4.6418 - val_accuracy: 0.3311 - val_loss: 2.3865\nEpoch 83/100\n46/46 - 10s - 221ms/step - accuracy: 0.3186 - loss: 4.2627 - val_accuracy: 0.3256 - val_loss: 2.6549\nEpoch 84/100\n46/46 - 11s - 232ms/step - accuracy: 0.3162 - loss: 4.1367 - val_accuracy: 0.3278 - val_loss: 2.4575\nEpoch 85/100\n46/46 - 8s - 176ms/step - accuracy: 0.3150 - loss: 4.7305 - val_accuracy: 0.3289 - val_loss: 2.0919\nEpoch 86/100\n46/46 - 10s - 222ms/step - accuracy: 0.3145 - loss: 4.2551 - val_accuracy: 0.3311 - val_loss: 1.9337\nEpoch 87/100\n46/46 - 8s - 179ms/step - accuracy: 0.3217 - loss: 3.9533 - val_accuracy: 0.3278 - val_loss: 2.6238\nEpoch 88/100\n46/46 - 10s - 221ms/step - accuracy: 0.3095 - loss: 4.1167 - val_accuracy: 0.3267 - val_loss: 1.8682\nEpoch 89/100\n46/46 - 8s - 176ms/step - accuracy: 0.3189 - loss: 3.6479 - val_accuracy: 0.3256 - val_loss: 1.9054\nEpoch 90/100\n46/46 - 10s - 224ms/step - accuracy: 0.3200 - loss: 3.5276 - val_accuracy: 0.3289 - val_loss: 1.8965\nEpoch 91/100\n46/46 - 11s - 229ms/step - accuracy: 0.3211 - loss: 3.5396 - val_accuracy: 0.3256 - val_loss: 1.8512\nEpoch 92/100\n46/46 - 10s - 212ms/step - accuracy: 0.3192 - loss: 3.7694 - val_accuracy: 0.3223 - val_loss: 1.8991\nEpoch 93/100\n46/46 - 8s - 173ms/step - accuracy: 0.3209 - loss: 3.6851 - val_accuracy: 0.3311 - val_loss: 1.9023\nEpoch 94/100\n46/46 - 8s - 184ms/step - accuracy: 0.3228 - loss: 3.4950 - val_accuracy: 0.3289 - val_loss: 1.9174\nEpoch 95/100\n46/46 - 10s - 217ms/step - accuracy: 0.3211 - loss: 3.2772 - val_accuracy: 0.3300 - val_loss: 1.9734\nEpoch 96/100\n46/46 - 8s - 176ms/step - accuracy: 0.3214 - loss: 3.6757 - val_accuracy: 0.3322 - val_loss: 1.8125\nEpoch 97/100\n46/46 - 8s - 177ms/step - accuracy: 0.3178 - loss: 3.6322 - val_accuracy: 0.3311 - val_loss: 1.8241\nEpoch 98/100\n46/46 - 11s - 236ms/step - accuracy: 0.3167 - loss: 3.3767 - val_accuracy: 0.3300 - val_loss: 1.9164\nEpoch 99/100\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 評估訓練結果","metadata":{}},{"cell_type":"code","source":"def show_train_history(train_history, train, validation):\n\n    plt.plot(train_history.history[train])\n\n    plt.plot(train_history.history[validation])\n\n    plt.title('Train History')\n\n    plt.ylabel('train')\n\n    plt.xlabel('Epoch')\n\n    plt.legend(['train', 'validation'], loc='upper left')\n\n    plt.show()\n    \n\nshow_train_history(train_history, 'accuracy', 'val_accuracy')\nshow_train_history(train_history, 'loss', 'val_loss')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 使用未參與訓練的測試資料測試，模型準確率","metadata":{}},{"cell_type":"code","source":"scores = model.evaluate(X_test,y_test,verbose=0)\n\nprint('Accuracy = ', scores[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 評估訓練結果","metadata":{}},{"cell_type":"code","source":"y_pred = np.argmax(model.predict(X_test), axis=-1)\ny_true = np.argmax(y_test, axis=-1)\nconfusion_matrix = confusion_matrix(y_true, y_pred)\n\nplt.figure(figsize=(10,7))\nsns.heatmap(confusion_matrix, annot=True, fmt='d')\nplt.xlabel('Predicted')\nplt.ylabel('Truth')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}